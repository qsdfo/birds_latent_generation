{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hourly-spanish",
   "metadata": {},
   "source": [
    "# Contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "western-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avgn.pytorch.dataset.spectro_dataset import SpectroDataset\n",
    "from avgn.pytorch.generate.interpolation import constant_radius_interpolation\n",
    "import random\n",
    "from main_spectrogramming import process_syllable\n",
    "from avgn.signalprocessing.dynamic_thresholding_scipy import dynamic_threshold_segmentation\n",
    "from avgn.signalprocessing.create_spectrogram_dataset import prepare_wav\n",
    "import librosa\n",
    "from avgn.pytorch.getters import get_model_and_dataset\n",
    "from avgn.signalprocessing.spectrogramming_scipy import _db_to_amplitude, _denormalize, _mel_to_linear, _min_level_db, build_mel_basis, build_mel_inversion_basis, inv_spectrogram_sp, griffinlim_sp\n",
    "from avgn.utils.cuda_variable import cuda_variable\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chunks\n",
    "def get_chunks(path, hparams):\n",
    "    # mel basis\n",
    "    mel_basis = build_mel_basis(hparams, hparams.sr, hparams.sr)\n",
    "    # load file\n",
    "    x_s, _ = prepare_wav(wav_loc=path, hparams=hparams, debug=False)\n",
    "    # Segmentation params\n",
    "    min_level_db_floor = -30\n",
    "    db_delta = 5\n",
    "    silence_threshold = 0.01\n",
    "    min_silence_for_spec = 0.05\n",
    "    max_vocal_for_spec = 1.0,\n",
    "    min_syllable_length_s = 0.05\n",
    "    # segment\n",
    "    results = dynamic_threshold_segmentation(\n",
    "        x_s,\n",
    "        hparams.sr,\n",
    "        n_fft=hparams.n_fft,\n",
    "        hop_length=hparams.hop_length_samples,\n",
    "        win_length=hparams.win_length_samples,\n",
    "        min_level_db_floor=min_level_db_floor,\n",
    "        db_delta=db_delta,\n",
    "        ref_level_db=hparams.ref_level_db,\n",
    "        pre=hparams.preemphasis,\n",
    "        min_silence_for_spec=min_silence_for_spec,\n",
    "        max_vocal_for_spec=max_vocal_for_spec,\n",
    "        silence_threshold=silence_threshold,\n",
    "        verbose=False,\n",
    "        min_syllable_length_s=min_syllable_length_s,\n",
    "        spectral_range=[hparams.mel_lower_edge_hertz, hparams.mel_upper_edge_hertz],\n",
    "    )\n",
    "    if results is None:\n",
    "        print('Cannot segment the input file')\n",
    "        return\n",
    "    # chunks\n",
    "    start_times = results[\"onsets\"]\n",
    "    end_times = results[\"offsets\"]\n",
    "    chunks_mS = []\n",
    "    start_samples = []\n",
    "    end_samples = []\n",
    "    for start_time, end_time in zip(start_times, end_times):\n",
    "        start_sample = int(start_time * hparams.sr)\n",
    "        end_sample = int(end_time * hparams.sr)\n",
    "        syl = x_s[start_sample:end_sample]\n",
    "\n",
    "        # To avoid mistakes, reproduce the whole preprocessing pipeline, even (here useless) int casting\n",
    "        _, mS, _ = process_syllable(syl, hparams, mel_basis=mel_basis, debug=False)\n",
    "        if mS is None:\n",
    "            continue\n",
    "        mS_int = (mS * 255).astype('uint8')\n",
    "        sample = SpectroDataset.process_mSp(mS_int)\n",
    "\n",
    "        chunks_mS.append(sample)\n",
    "        start_samples.append(start_sample)\n",
    "        end_samples.append(end_sample)\n",
    "    return x_s, chunks_mS, start_samples, end_samples"
   ]
  },
  {
   "source": [
    "## Set model and material"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "quiet-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"models/VAE_voizo_2021-04-06_15-23-04/config.py\"\n",
    "loading_epoch = 1750\n",
    "source_path = '/home/leo/Code/birds_latent_generation/data/raw/voizo_chunks/Nigthingale/XCcommonNightingale-Denoised/Nightingale1_0_0.wav'\n",
    "contamination_path = '/home/leo/Code/birds_latent_generation/data'\\\n",
    "    '/raw/voizo_chunks/Corvus/XCcorvus-Denoised/Kraai_BieslNp_120312-07xc_0_0.wav'\n",
    "contamination_parameters = {\n",
    "    'p_contamination': 0.5,\n",
    "}\n",
    "method = 'linear'"
   ]
  },
  {
   "source": [
    "## Generate contamination"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c8ed0355d31d>, line 70)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c8ed0355d31d>\"\u001b[0;36m, line \u001b[0;32m70\u001b[0m\n\u001b[0;31m    x_center =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model, _, _, _, hparams, _, _, config_path = get_model_and_dataset(\n",
    "    config=config_path, loading_epoch=loading_epoch)\n",
    "\n",
    "# load files\n",
    "source = {}\n",
    "source['path'] = source_path\n",
    "waveform, chunks, start_samples, end_samples = get_chunks(path=source['path'], hparams=hparams)\n",
    "source['waveform'] = waveform\n",
    "source['chunks'] = chunks\n",
    "source['start_samples'] = start_samples\n",
    "source['end_samples'] = end_samples\n",
    "contamination = {}\n",
    "contamination['path'] = contamination_path\n",
    "waveform, chunks, start_samples, end_samples = get_chunks(path=contamination['path'], hparams=hparams)\n",
    "contamination['waveform'] = waveform\n",
    "contamination['chunks'] = chunks\n",
    "contamination['start_samples'] = start_samples\n",
    "contamination['end_samples'] = end_samples\n",
    "\n",
    "# Choose which samples to contaminate and by which degree\n",
    "contamination_indices = []\n",
    "contamination_degrees = []\n",
    "xs = []\n",
    "ys = []\n",
    "p_contamination = contamination_parameters['p_contamination']\n",
    "for index, chunk in enumerate(source['chunks']):\n",
    "    if random.random() < p_contamination:\n",
    "        contamination_indices.append(index)\n",
    "        contamination_degrees.append(random.random())\n",
    "        xs.append(chunk)\n",
    "        # choose (randomly?) a contaminating syllable\n",
    "        ys.append(random.choice(contamination['chunks']))\n",
    "xs_cuda = cuda_variable(torch.tensor(np.stack(xs)))\n",
    "ys_cuda = cuda_variable(torch.tensor(np.stack(ys)))\n",
    "\n",
    "# Encode\n",
    "mu, logvar = model.encode(xs_cuda)\n",
    "x_z = model.reparameterize(mu, logvar)\n",
    "mu, logvar = model.encode(ys_cuda)\n",
    "y_z = model.reparameterize(mu, logvar)\n",
    "z_out = torch.zeros_like(x_z)\n",
    "\n",
    "# Contaminate\n",
    "for batch_ind, t in enumerate(contamination_degrees):\n",
    "    if method == 'linear':\n",
    "        z_out[batch_ind] = x_z[batch_ind] * (1 - t) + y_z[batch_ind] * t\n",
    "    elif method == 'constant_radius':\n",
    "        z_out[batch_ind] = constant_radius_interpolation(x_z[batch_ind], y_z[batch_ind], t)\n",
    "# Decode z\n",
    "x_recon = model.decode(z_out).cpu().detach().numpy()\n",
    "\n",
    "# Replace contamined samples in original wave\n",
    "out_wave = source['waveform'].copy()\n",
    "mel_basis = build_mel_basis(hparams, hparams.sr, hparams.sr)\n",
    "mel_inversion_basis = build_mel_inversion_basis(mel_basis)\n",
    "for batch_index, contamination_index in enumerate(contamination_indices):\n",
    "    new_chunk = x_recon[batch_index, 0]\n",
    "    s_unnorm = _denormalize(\n",
    "        new_chunk, min_db=_min_level_db(), max_db=hparams.ref_level_db)\n",
    "    s_amplitude = _db_to_amplitude(s_unnorm + hparams.ref_level_db)\n",
    "    s_linear = _mel_to_linear(\n",
    "        s_amplitude, _mel_inverse_basis=mel_inversion_basis)**(1 / hparams.power)\n",
    "\n",
    "    # Calculer la dimension de la syllabe générée (rms energy)\n",
    "    rms_energy = librosa.feature.rms(S=s_linear, frame_length=hparams.win_length_samples,\n",
    "                                     hop_length=hparams.hop_length_samples)\n",
    "    rms_energy = rms_energy[0, :]\n",
    "    rms_energy_norm = rms_energy / (rms_energy.max() + 1e-12)\n",
    "    non_silence_indices = np.where(rms_energy_norm > 0.05)[0]\n",
    "    start_index = non_silence_indices.min()\n",
    "    end_index = non_silence_indices.max()\n",
    "    s_chunk = s_linear[:, start_index:end_index]\n",
    "\n",
    "    # griffin-lim\n",
    "    x_grif = griffinlim_sp(s_chunk, n_fft=hparams.n_fft,\n",
    "                           win_length=hparams.win_length_samples, hop_length=hparams.hop_length_samples)\n",
    "\n",
    "    # Match gain\n",
    "    start_sample = source['start_samples'][contamination_index]\n",
    "    end_sample = source['end_samples'][contamination_index]\n",
    "    y = out_wave[start_sample:end_sample]\n",
    "    # gain_source = np.abs(y).max()\n",
    "    # gain_target = np.abs(x_grif).max()\n",
    "    gain_source = librosa.feature.rms(y).max()\n",
    "    gain_target = librosa.feature.rms(x_grif).max()\n",
    "    if gain_target > gain_source:\n",
    "        x_norm = x_grif * gain_source / gain_target\n",
    "\n",
    "    # Insérer\n",
    "    out_wave = np.concatenate(\n",
    "        (out_wave[:start_sample], x_norm, out_wave[end_sample:])\n",
    "    )\n",
    "\n",
    "ipd.display(\n",
    "        ipd.Audio(source['waveform'], rate=hparams.sr),\n",
    "        ipd.Audio(contamination['waveform'], rate=hparams.sr),\n",
    "        ipd.Audio(out_wave, rate=hparams.sr),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd09c813e7a3cfc735070c2c66bb40b11de1583eee1e9c394ef2fdc0a1f40d2aeae",
   "display_name": "Python 3.8.2  ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "9c813e7a3cfc735070c2c66bb40b11de1583eee1e9c394ef2fdc0a1f40d2aeae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}